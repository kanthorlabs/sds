# Ideas

We have three consistency levels for writes: in-memory only, local disk only, and remote object storage. But the abstraction could allow for more levels in the future. The principles are: the slower layer you write to, the more durable the write is. We could have levels like "replicated local disk" (write to multiple local disks for higher durability), or "erasure coded remote storage" (write to multiple object storage backends with erasure coding for higher durability).

So that, if we have a struct `Block`, instead of using a struct `Page` to hold data in memory, we will read the data of the `Block` in slower layers into the `Block` of the most fastest layer available.

Then write is the opposite behavior: we write to the fastest layer first, then write to the slower layers synchronously or asynchronously depending on the consistency level chosen.

Questions:

1. What the fuck is file size in Object Storage will we allow?
2. How can we resolve write conflicts? 
    - We can use "verifying" (optimistic) technique: Ask for update permission (SELECT ... FOR UPDATE) by writing lock to lock table, then modify what you need. Other click must respect the lock you have obtained. We can borrow the idea of Transaction Isolation: Read uncommitted, Read committed, Repeatable read and Serializable. Check https://www.postgresql.org/docs/current/transaction-iso.html for more details. In the end of the day, we will have both SLock and XLock.
    - We can also use Log-Structured Merge-Tree for other kind of data. For example an event in event streaming